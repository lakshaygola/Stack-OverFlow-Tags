{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StackOverFlow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshaygola/Stack-OverFlow-Tags/blob/main/StackOverFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzybTbm72Kl3"
      },
      "source": [
        "# Stack Overflow Tag Prediction\n",
        "\n",
        "In this notebook we create the model which help us to predict the tag of the question posted on the stack overflow website\n",
        "\n",
        "This tag can be helpfull to the user to classify the question and also help them to search the question according to the tags\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0aHXLdwZ3qDz"
      },
      "source": [
        "# Importing some necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.utils import shuffle\n",
        "import os"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXeo82jf2GK6",
        "outputId": "87e2669c-2f5a-4afe-b550-1610640a9749"
      },
      "source": [
        "# Let download the dataset from the Bigquery\n",
        "!gsutil cp 'gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv' ./"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://cloudml-demo-lcm/SO_ml_tags_avocado_188k_v2.csv...\n",
            "\\ [1 files][276.7 MiB/276.7 MiB]                                                \n",
            "Operation completed over 1 objects/276.7 MiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "a9Cin41l2KNx",
        "outputId": "dd50f22d-e1b2-4077-9f98-bc98789edd9f"
      },
      "source": [
        "# Reading the data\n",
        "data = pd.read_csv('SO_ml_tags_avocado_188k_v2.csv',\n",
        "                   names= ['tags', 'original tags', 'text'], \n",
        "                   header = 0)\n",
        "\n",
        "# Shuffling the data\n",
        "data = shuffle(data, random_state = 20)\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>original tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70357</th>\n",
              "      <td>pandas</td>\n",
              "      <td>python,mysql,pandas,sqlalchemy</td>\n",
              "      <td>sqlalchemy is too slow, did i do anything wron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152810</th>\n",
              "      <td>tensorflow</td>\n",
              "      <td>python-2.7,tensorflow,pip,anaconda</td>\n",
              "      <td>getting \"no module named queue\" when installin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180803</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>python,tensorflow,keras,classification,cross-e...</td>\n",
              "      <td>why does sigmoid &amp; crossentropy of avocado/avo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186450</th>\n",
              "      <td>pandas,matplotlib</td>\n",
              "      <td>python,pandas,matplotlib</td>\n",
              "      <td>plot avocado columns with secondary y -axis an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52130</th>\n",
              "      <td>pandas</td>\n",
              "      <td>python,pandas,parsing</td>\n",
              "      <td>“unknown string format”-error when parsing url...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     tags  ...                                               text\n",
              "70357              pandas  ...  sqlalchemy is too slow, did i do anything wron...\n",
              "152810         tensorflow  ...  getting \"no module named queue\" when installin...\n",
              "180803   tensorflow,keras  ...  why does sigmoid & crossentropy of avocado/avo...\n",
              "186450  pandas,matplotlib  ...  plot avocado columns with secondary y -axis an...\n",
              "52130              pandas  ...  “unknown string format”-error when parsing url...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "NyxGzrc_5oop",
        "outputId": "0c4b5c83-8c5a-4d82-a503-8ff88873d013"
      },
      "source": [
        "# Droping the original tags columns and all the NaN values from the dataset\n",
        "data = data.drop('original tags', axis=1)\n",
        "data.dropna()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tags</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70357</th>\n",
              "      <td>pandas</td>\n",
              "      <td>sqlalchemy is too slow, did i do anything wron...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152810</th>\n",
              "      <td>tensorflow</td>\n",
              "      <td>getting \"no module named queue\" when installin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180803</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>why does sigmoid &amp; crossentropy of avocado/avo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186450</th>\n",
              "      <td>pandas,matplotlib</td>\n",
              "      <td>plot avocado columns with secondary y -axis an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52130</th>\n",
              "      <td>pandas</td>\n",
              "      <td>“unknown string format”-error when parsing url...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178569</th>\n",
              "      <td>tensorflow,keras</td>\n",
              "      <td>avocado lstm, is the time_step equal to 1 like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31962</th>\n",
              "      <td>pandas</td>\n",
              "      <td>new to avocado, need to create a df from 2 oth...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23775</th>\n",
              "      <td>pandas</td>\n",
              "      <td>adding rows to a avocado dataframe from anothe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37135</th>\n",
              "      <td>pandas</td>\n",
              "      <td>how to lag data by x specific days on a multi ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92634</th>\n",
              "      <td>pandas</td>\n",
              "      <td>avocado: merge dataframes based on multi-level...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>188199 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                     tags                                               text\n",
              "70357              pandas  sqlalchemy is too slow, did i do anything wron...\n",
              "152810         tensorflow  getting \"no module named queue\" when installin...\n",
              "180803   tensorflow,keras  why does sigmoid & crossentropy of avocado/avo...\n",
              "186450  pandas,matplotlib  plot avocado columns with secondary y -axis an...\n",
              "52130              pandas  “unknown string format”-error when parsing url...\n",
              "...                   ...                                                ...\n",
              "178569   tensorflow,keras  avocado lstm, is the time_step equal to 1 like...\n",
              "31962              pandas  new to avocado, need to create a df from 2 oth...\n",
              "23775              pandas  adding rows to a avocado dataframe from anothe...\n",
              "37135              pandas  how to lag data by x specific days on a multi ...\n",
              "92634              pandas  avocado: merge dataframes based on multi-level...\n",
              "\n",
              "[188199 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19CYNELK6hHP",
        "outputId": "69029a1a-d2ac-4189-a0e9-e3c3a172b268"
      },
      "source": [
        "# Some of the tags are comma separted lets create the list of the following\n",
        "tag_splits = [tag.split(',') for tag in data['tags']] \n",
        "print(tag_splits[:15])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['pandas'], ['tensorflow'], ['tensorflow', 'keras'], ['pandas', 'matplotlib'], ['pandas'], ['matplotlib'], ['scikitlearn'], ['pandas'], ['pandas'], ['pandas'], ['pandas'], ['pandas'], ['pandas'], ['pandas'], ['pandas']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dc6KjcRd7IaW",
        "outputId": "ce004341-dc5e-4805-c842-22d9034c0c0b"
      },
      "source": [
        "# Making the tags into numeric values such that we can pass them in model\n",
        "tags_encoder = MultiLabelBinarizer()\n",
        "tags_encoded= tags_encoder.fit_transform(tag_splits)\n",
        "num_tags = len(tags_encoded[0])\n",
        "print(num_tags)\n",
        "print(tags_encoded[0])\n",
        "print(tags_encoder.classes_)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "[0 0 1 0 0]\n",
            "['keras' 'matplotlib' 'pandas' 'scikitlearn' 'tensorflow']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRMpEHQI82GY"
      },
      "source": [
        "# Perform train and test split of the tags\n",
        "train_size = int(len(data) * 0.8)         # Converting the whole value in integer so that we dont get decimal value\n",
        "train_tags = tags_encoded[:train_size]\n",
        "test_tags = tags_encoded[train_size:]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhbvzK9u90ZO",
        "outputId": "42186163-4be9-4d7c-aba6-dff13fa1321f"
      },
      "source": [
        "# Number of rows on train data and test data\n",
        "print('Train data size: ', train_size)\n",
        "print('Test data size: ', len(data) - train_size)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data size:  150559\n",
            "Test data size:  37640\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PopKtl96-gGQ"
      },
      "source": [
        "# Making class to perfrom preprocessing on the text data\n",
        "# Creating the tokenizer then converting the text data into a matrix\n",
        "\n",
        "class textpreprocessing(object):\n",
        "  def __init__(self, vocal_size):\n",
        "      self.vocal_size_ = vocal_size\n",
        "      self.tokenizer_ = None\n",
        "\n",
        "  def tokenizer_formation(self, txt):\n",
        "      tokenizer = text.Tokenizer(num_words= self.vocal_size_)\n",
        "      tokenizer.fit_on_texts(txt)\n",
        "      self.tokenizer_= tokenizer\n",
        "\n",
        "  def tokenizer_matrix(self, txt_list):\n",
        "    text_matrix = self.tokenizer_.texts_to_matrix(txt_list)\n",
        "    return text_matrix"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QzSZfWQBsAM"
      },
      "source": [
        "# Spliting the text data \n",
        "\n",
        "vocal_size= 400\n",
        "\n",
        "train_txt = data['text'].values[:train_size]\n",
        "test_txt = data['text'].values[train_size:]\n",
        "\n",
        "processor =  textpreprocessing(vocal_size)\n",
        "processor.tokenizer_formation(train_txt)\n",
        "\n",
        "train_body = processor.tokenizer_matrix(train_txt)\n",
        "test_body = processor.tokenizer_matrix(test_body)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqrkaT_QBsoC",
        "outputId": "42619771-2ec5-4c2c-c298-cfb06eef14d3"
      },
      "source": [
        "# let see the train data\n",
        "print(len(train_body[0]))\n",
        "print(train_body[0])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400\n",
            "[0. 1. 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
            " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            " 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8aPEd-cG3HQ"
      },
      "source": [
        "# Save the tokenizer (so we dont have to mak BOW)\n",
        "import pickle\n",
        "\n",
        "with open ('./processor_state.pkl', 'wb') as f:\n",
        "  pickle.dump(processor, f)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNvyYxvpZtr0"
      },
      "source": [
        "# Creating the model and train it on train data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIb4EU3EZm0d"
      },
      "source": [
        "# Creating the model\n",
        "def create_model(vocal_size, num_tags):\n",
        "\n",
        "    model= tf.keras.models.Sequential()\n",
        "    model.add(layers.Dense(50, input_shape = (vocal_size, ), activation = 'relu'))\n",
        "    model.add(layers.Dense(25, activation = 'relu'))\n",
        "    model.add(layers.Dense(num_tags, activation = 'sigmoid'))\n",
        "\n",
        "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3Rd_N71eyqW",
        "outputId": "1343f5ae-be23-4af8-d29b-178825bde3db"
      },
      "source": [
        "# Collect the summary of the model\n",
        "model = create_model(vocal_size, num_tags)\n",
        "model.summary()\n",
        "\n",
        "# Train and evaluate the model\n",
        "model.fit(train_body, train_tags, epochs = 3, validation_split = 0.1, batch_size = 128)\n",
        "model_result = model.evaluate(test_body, test_tags, batch_size = 128)\n",
        "print('Evaluation  Loss: {},  accuracy: {}'.format(model_result[0], model_result[1]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 50)                20050     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 5)                 130       \n",
            "=================================================================\n",
            "Total params: 21,455\n",
            "Trainable params: 21,455\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "1059/1059 [==============================] - 3s 3ms/step - loss: 0.2323 - accuracy: 0.7678 - val_loss: 0.1147 - val_accuracy: 0.8892\n",
            "Epoch 2/3\n",
            "1059/1059 [==============================] - 2s 2ms/step - loss: 0.1075 - accuracy: 0.8910 - val_loss: 0.1079 - val_accuracy: 0.8977\n",
            "Epoch 3/3\n",
            "1059/1059 [==============================] - 2s 2ms/step - loss: 0.0991 - accuracy: 0.8989 - val_loss: 0.1051 - val_accuracy: 0.8939\n",
            "295/295 [==============================] - 0s 1ms/step - loss: 0.1019 - accuracy: 0.8968\n",
            "Evaluation  Loss: 0.10187453776597977,  accuracy: 0.896785318851471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsOqdH4QoQ5m"
      },
      "source": [
        "# Saving the modsl in the file\n",
        "model.save('stackoverflow_model.h5')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lLwFnuZGx8s"
      },
      "source": [
        "# Taking Prediction from the model\n",
        "\n",
        "Here we have one question which is not present in our dataset we will take the prediction on that question.\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuLp19ujNehR"
      },
      "source": [
        "# Question on which we will take the prediction\n",
        "\n",
        "test_requests = [\n",
        "  \"How to preprocess strings in Keras models Lambda layer? I have the problem that the value passed on to the Lambda layer (at compile time) is a placeholder generated by keras (without values). When the model is compiled, the .eval () method throws the error: You must feed a value for placeholder tensor 'input_1' with dtype string and shape [?, 1] def text_preprocess(x): strings = tf.keras.backend.eval(x) vectors = [] for string in strings: vector = string_to_one_hot(string.decode('utf-8')) vectors.append(vector) vectorTensor = tf.constant(np.array(vectors),dtype=tf.float32) return vectorTensor input_text = Input(shape=(1,), dtype=tf.string) embedding = Lambda(text_preprocess)(input_text) dense = Dense(256, activation='relu')(embedding) outputs = Dense(2, activation='softmax')(dense) model = Model(inputs=[input_text], outputs=outputs) model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy']) model.summary() model.save('test.h5') If I pass a string array into the input layer statically, I can compile the model, but I get the same error if I want to convert the model to tflite. #I replaced this line: input_text = Input(shape=(1,), dtype=tf.string) #by this lines: test = tf.constant(['Hello', 'World']) input_text = Input(shape=(1,), dtype=tf.string, tensor=test) #but calling this ... converter = TFLiteConverter.from_keras_model_file('string_test.h5') tfmodel = converter.convert() #... still leads to this error: InvalidArgumentError: You must feed a value for placeholder tensor 'input_3' with dtype string and shape [2] [[{{node input_3}}]] \",\n",
        "  \"Change the bar item name in Pandas I have a test excel file like: df = pd.DataFrame({'name':list('abcdefg'), 'age':[10,20,5,23,58,4,6]}) print (df) name  age 0    a   10 1    b   20 2    c    5 3    d   23 4    e   58 5    f    4 6    g    6 I use Pandas and matplotlib to read and plot it: import pandas as pd import numpy as np import matplotlib.pyplot as plt import os excel_file = 'test.xlsx' df = pd.read_excel(excel_file, sheet_name=0) df.plot(kind='bar') plt.show() the result shows: enter image description here it use index number as item name, how can I change it to the name, which stored in column name?\"\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLpz_O3P5A93"
      },
      "source": [
        "# Defining class to take the prediction \n",
        "\n",
        "class CustomOutput(object):\n",
        "  def __init__(self, model, processor):\n",
        "    self.model_ = model\n",
        "    self.processor_ = processor\n",
        "  \n",
        "  def predicition(self, data):\n",
        "    preprocess_data = self.processor_.tokenizer_matrix(data)\n",
        "    prediction = self.model_.predict(preprocess_data)\n",
        "    return prediction.tolist() "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdQDSrj1M8ME",
        "outputId": "06f75f80-e00b-4f13-e7d7-e6256226e8c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Taking prediction\n",
        "\n",
        "classifier = CustomOutput(model, processor)\n",
        "outputs = classifier.predicition(test_requests)\n",
        "print(outputs)\n",
        "\n",
        "# For loop to print the tags\n",
        "for i in range(len(outputs)):\n",
        "  print('Prediction Tags: ')\n",
        "  for idx, tag in enumerate(outputs[i]):\n",
        "    if tag > 0.7:\n",
        "      print(tags_encoder.classes_[idx])\n",
        "  print('\\n')"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.9738432168960571, 0.0001360476016998291, 0.0003139376640319824, 0.00040218234062194824, 0.58158278465271], [1.9019031242351048e-05, 0.5976572036743164, 0.8521859645843506, 0.0003109574317932129, 3.447831841185689e-05]]\n",
            "Prediction Tags: \n",
            "keras\n",
            "\n",
            "\n",
            "Prediction Tags: \n",
            "pandas\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-GmooTAT41u"
      },
      "source": [
        "# Visualising Model\n",
        "\n",
        "In this section we will visualise the model and how its able to predict the tags in order to do this we have to install two more libraries \n",
        "\n",
        "SHAP and COLOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8XY57tcNsMK",
        "outputId": "7f8beb5b-f282-4600-cf14-2d0cf2745c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        }
      },
      "source": [
        "!pip install shap\n",
        "!pip install color"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting shap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b9/f4/c5b95cddae15be80f8e58b25edceca105aa83c0b8c86a1edad24a6af80d3/shap-0.39.0.tar.gz (356kB)\n",
            "\r\u001b[K     |█                               | 10kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 8.8MB/s eta 0:00:01\r\u001b[K     |██▊                             | 30kB 7.1MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 4.8MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 61kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 81kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 92kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 4.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from shap) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from shap) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from shap) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from shap) (1.1.5)\n",
            "Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.7/dist-packages (from shap) (4.41.1)\n",
            "Collecting slicer==0.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.7/dist-packages (from shap) (0.51.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from shap) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->shap) (1.0.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->shap) (2.8.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba->shap) (54.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba->shap) (0.34.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->shap) (1.15.0)\n",
            "Building wheels for collected packages: shap\n",
            "  Building wheel for shap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for shap: filename=shap-0.39.0-cp37-cp37m-linux_x86_64.whl size=491620 sha256=0bb555e1d2a07fafe0c899bd883e2f3b2d19ae8f9205b7cfa6b607e095babc60\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/27/f5/a8ab9da52fd159aae6477b5ede6eaaec69fd130fa0fa59f283\n",
            "Successfully built shap\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.39.0 slicer-0.0.7\n",
            "Collecting color\n",
            "  Downloading https://files.pythonhosted.org/packages/88/04/0defd6f424e5bafb5abc75510cbe119a85d80b5505f1de5cd9a16d89ba8c/color-0.1.1.tar.gz\n",
            "Collecting enum34\n",
            "  Downloading https://files.pythonhosted.org/packages/63/f6/ccb1c83687756aeabbf3ca0f213508fcfb03883ff200d201b3a4c60cedcc/enum34-1.1.10-py3-none-any.whl\n",
            "Building wheels for collected packages: color\n",
            "  Building wheel for color (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for color: filename=color-0.1-cp37-none-any.whl size=5025 sha256=8f0b687d3836ec858c1407feee77a4cfa6d7fd839571c53230d25bf747f18820\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/a3/55/b1b35e99d6e918f96044a5dddc015f6f93eb5d0ecb1fc3a055\n",
            "Successfully built color\n",
            "Installing collected packages: enum34, color\n",
            "Successfully installed color-0.1 enum34-1.1.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIkseJdhUgRR"
      },
      "source": [
        "import shap\n",
        "import color"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by_Cf-VPUkas"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}